{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "class TimetableEnv(Env):\n",
    "    def __init__(self, num_days, periods_per_day, lunch_after_period, teachers, classes):\n",
    "        # Inputs\n",
    "        self.num_days = num_days\n",
    "        self.periods_per_day = periods_per_day\n",
    "        self.lunch_after_period = lunch_after_period\n",
    "        self.teachers = teachers\n",
    "        self.classes = classes\n",
    "        \n",
    "        # Total periods (excluding lunch break)\n",
    "        self.total_periods = self.num_days * self.periods_per_day\n",
    "        \n",
    "        # Timetable: A 3D array [days][periods][classes]\n",
    "        self.timetable = np.full((num_days, periods_per_day, len(classes)), None)\n",
    "        \n",
    "        # RL state and action space\n",
    "        self.action_space = Discrete(len(teachers) * len(classes) * self.num_days * self.periods_per_day)\n",
    "        self.observation_space = Box(low=0, high=1, shape=(num_days, periods_per_day, len(classes)), dtype=int)\n",
    "        \n",
    "        # Remaining lectures for each class and teacher\n",
    "        self.remaining_lectures = {}\n",
    "        for class_name in classes:\n",
    "            print(f\"\\nFor {class_name}:\")\n",
    "            self.remaining_lectures[class_name] = {}\n",
    "            for teacher in teachers:\n",
    "                print(f\"  Teacher {teacher['name']} teaches: {', '.join(teacher['subjects'].keys())}\")\n",
    "                for subject, total_lectures in teacher['subjects'].items():\n",
    "                    num_lectures = int(input(f\"    Enter number of {subject} lectures for {class_name} (max {total_lectures}): \"))\n",
    "                    if teacher['name'] not in self.remaining_lectures[class_name]:\n",
    "                       self.remaining_lectures[class_name][teacher['name']] = {}\n",
    "                    self.remaining_lectures[class_name][teacher['name']][subject] = num_lectures\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset timetable and remaining lectures\n",
    "        self.timetable = np.full((self.num_days, self.periods_per_day, len(self.classes)), None)\n",
    "        self.remaining_lectures = {class_name: {teacher['name']: teacher['subjects'] for teacher in self.teachers} for class_name in self.classes}\n",
    "        return self.timetable\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Decode the action into teacher, class, day, and period\n",
    "        teacher_idx = action // (len(self.classes) * self.num_days * self.periods_per_day)\n",
    "        class_idx = (action % (len(self.classes) * self.num_days * self.periods_per_day)) // (self.num_days * self.periods_per_day)\n",
    "        day = (action % (self.num_days * self.periods_per_day)) // self.periods_per_day\n",
    "        period = action % self.periods_per_day\n",
    "        \n",
    "        teacher = self.teachers[teacher_idx]\n",
    "        class_name = self.classes[class_idx]\n",
    "        \n",
    "        # Check if valid action\n",
    "        if self.timetable[day, period, class_idx] is not None:\n",
    "            return self.timetable, -1, False, {}\n",
    "        \n",
    "        # Update timetable and remaining lectures\n",
    "        subject = None\n",
    "        for subj, count in self.remaining_lectures[class_name][teacher['name']].items():\n",
    "            if count > 0:\n",
    "                subject = subj\n",
    "                break\n",
    "        \n",
    "        if subject is None:\n",
    "            return self.timetable, -1, False, {}\n",
    "        \n",
    "        self.timetable[day, period, class_idx] = (teacher['code'], subject)\n",
    "        self.remaining_lectures[class_name][teacher['name']][subject] -= 1\n",
    "        \n",
    "        # Reward calculation\n",
    "        reward = 1\n",
    "        if period == self.lunch_after_period:\n",
    "            reward -= 0.5  # Discourage labs being split by lunch break\n",
    "        # Count occurrences of (teacher['code'], subject) in the timetable for the given class\n",
    "        occurrences = np.sum([\n",
    "            (self.timetable[day, period, class_idx] == (teacher['code'], subject)) \n",
    "            for day in range(self.num_days) \n",
    "            for period in range(self.periods_per_day)\n",
    "        ])\n",
    "        if occurrences > 1:\n",
    "            reward -= 0.5  # Discourage consecutive same subject\n",
    "\n",
    "            reward -= 0.5  # Discourage consecutive same subject\n",
    "        \n",
    "        # Check if all lectures are allocated\n",
    "        done = all(all(all(v == 0 for v in subj.values()) for subj in class_data.values()) for class_data in self.remaining_lectures.values())\n",
    "        \n",
    "        return self.timetable, reward, done, {}\n",
    "    \n",
    "    def render(self):\n",
    "        for class_idx, class_name in enumerate(self.classes):\n",
    "            print(f\"\\nTimetable for {class_name}:\")\n",
    "            for day in range(self.num_days):\n",
    "                print(f\"Day {day+1}: \", end=\"\")\n",
    "                for period in range(self.periods_per_day):\n",
    "                    if self.timetable[day, period, class_idx]:\n",
    "                        print(self.timetable[day, period, class_idx], end=\" | \")\n",
    "                    else:\n",
    "                        print(\"Free\", end=\" | \")\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RLAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.q_table = np.zeros((env.observation_space.shape[0], env.action_space.n))\n",
    "        self.alpha = 0.1  # Learning rate\n",
    "        self.gamma = 0.9  # Discount factor\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.min_epsilon = 0.01\n",
    "    \n",
    "    def train(self, episodes):\n",
    "        for episode in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                if random.uniform(0, 1) < self.epsilon:\n",
    "                    action = self.env.action_space.sample()  # Explore\n",
    "                else:\n",
    "                    action = np.argmax(self.q_table[state])  # Exploit\n",
    "                \n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                self.q_table[state, action] = (1 - self.alpha) * self.q_table[state, action] + \\\n",
    "                                              self.alpha * (reward + self.gamma * np.max(self.q_table[next_state]))\n",
    "                state = next_state\n",
    "            \n",
    "            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 10a:\n",
      "  Teacher jalpa teaches: os\n",
      "  Teacher nishant teaches: ml\n",
      "\n",
      "For 10b:\n",
      "  Teacher jalpa teaches: os\n",
      "  Teacher nishant teaches: ml\n"
     ]
    }
   ],
   "source": [
    "# Accept timetable structure\n",
    "num_days = int(input(\"Enter the number of days: \"))\n",
    "periods_per_day = int(input(\"Enter the number of periods in one day: \"))\n",
    "lunch_after_period = int(input(\"Enter the period number after which lunch break occurs: \"))\n",
    "\n",
    "# Accept teacher information\n",
    "num_teachers = int(input(\"Enter the number of teachers: \"))\n",
    "teachers = []\n",
    "for i in range(num_teachers):\n",
    "    teacher_name = input(f\"Enter name for Teacher {i+1}: \")\n",
    "    teacher_code = input(f\"Enter code for Teacher {i+1}: \")\n",
    "    num_subjects = int(input(f\"Enter the number of subjects Teacher {teacher_name} teaches: \"))\n",
    "    subjects = {}\n",
    "    for j in range(num_subjects):\n",
    "        subject_name = input(f\"  Enter subject {j+1} name: \")\n",
    "        num_lectures = int(input(f\"  Enter number of lectures for {subject_name} in a week: \"))\n",
    "        subjects[subject_name] = num_lectures\n",
    "    teachers.append({\"name\": teacher_name, \"code\": teacher_code, \"subjects\": subjects})\n",
    "\n",
    "# Accept class information\n",
    "num_classes = int(input(\"Enter the number of classes: \"))\n",
    "classes = []\n",
    "for i in range(num_classes):\n",
    "    class_name = input(f\"Enter name for Class {i+1}: \")\n",
    "    classes.append(class_name)\n",
    "\n",
    "# Initialize the environment\n",
    "env = TimetableEnv(\n",
    "    num_days=num_days, \n",
    "    periods_per_day=periods_per_day, \n",
    "    lunch_after_period=lunch_after_period, \n",
    "    teachers=teachers, \n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "agent = RLAgent(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36mRLAgent.train\u001b[1;34m(self, episodes)\u001b[0m\n\u001b[0;32m     21\u001b[0m         action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_table[state])  \u001b[38;5;66;03m# Exploit\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_table[state, action] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     25\u001b[0m                                   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m (reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_table[next_state]))\n\u001b[0;32m     26\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_epsilon, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_decay)\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "agent.train(episodes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = np.argmax(agent.q_table)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "env.render()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
